{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this initial implementation, we utilized a dataset comprising over 20,000 English-Arabic sentence pairs. This dataset served as the foundation for training our Transformer-based machine translation model. The model achieved an average BLEU score of approximately 0.23, indicating that it could capture basic translation patterns but had limitations in handling more complex or nuanced sentences.\n",
        "\n",
        "A significant challenge was the dataset's limited size and diversity. While 20,000 sentences provide a starting point, it is relatively small compared to the extensive corpora used in state-of-the-art machine translation systems, which often involve millions of sentence pairs. This limitation restricts the model's exposure to a wide range of vocabulary, idiomatic expressions, and varied syntactic structures. Such exposure is crucial, especially when translating between English and Arabic, due to their linguistic differences and the morphological richness of Arabic.\n",
        "\n",
        "To enhance the model's performance, it is essential to acquire more extensive and diverse datasets. Additional high-quality data would enable the model to learn a broader vocabulary and better understand context, leading to more accurate and fluent translations. Moreover, increasing computational resources would allow for training deeper models with larger embedding dimensions and more Transformer layers, which could capture the complexities of both languages more effectively.\n",
        "\n",
        "Investing in these areas—expanding the dataset and utilizing more computational power—would address the current limitations. It would significantly improve the model's ability to handle complex sentence structures, idiomatic expressions, and the nuanced linguistic patterns necessary for high-quality machine translation between English and Arabic."
      ],
      "metadata": {
        "id": "iMU5RFKKNaSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n"
      ],
      "metadata": {
        "id": "WwouRog5NcCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d268a9d-b02a-4660-ebc0-cfc30d8894d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Data Preparation\n",
        "Tokenization:\n",
        "\n",
        "Tokenize the English and Arabic sentences separately.\n",
        "Consider using subword tokenization (e.g., Byte-Pair Encoding or WordPiece) to handle out-of-vocabulary words. This is especially useful for Arabic, as it has complex morphology.\n",
        "Vocabulary Creation:\n",
        "\n",
        "Create separate vocabularies for English and Arabic tokens.\n",
        "Map each token to a unique integer for use in the model.\n",
        "Padding and Batching:\n",
        "\n",
        "Pad sequences to a fixed length to handle variable-length inputs and outputs.\n",
        "Group similar-length sentences in batches to optimize training speed and memory use."
      ],
      "metadata": {
        "id": "l93azZWqNfN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences = []\n",
        "arabic_sentences = []\n",
        "\n",
        "with open('ara_eng.txt', 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        eng, ara = line.strip().split('\\t')\n",
        "        english_sentences.append(eng)\n",
        "        arabic_sentences.append(ara)\n",
        "\n",
        "print(\"Sample English Sentence:\", english_sentences[0])\n",
        "print(\"Sample Arabic Sentence:\", arabic_sentences[0])\n"
      ],
      "metadata": {
        "id": "_KCx5KLuNgKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e34edcfe-0d17-4cdb-babe-4cb8cbfd34f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample English Sentence: Hi.\n",
            "Sample Arabic Sentence: مرحبًا.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('english_sentences.txt', 'w', encoding='utf-8') as eng_file:\n",
        "    for sentence in english_sentences:\n",
        "        eng_file.write(sentence + '\\n')\n",
        "\n",
        "with open('arabic_sentences.txt', 'w', encoding='utf-8') as ara_file:\n",
        "    for sentence in arabic_sentences:\n",
        "        ara_file.write(sentence + '\\n')\n"
      ],
      "metadata": {
        "id": "TGqzY_YrO8jg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "spm.SentencePieceTrainer.Train(input='english_sentences.txt', model_prefix='eng_tokenizer', vocab_size=8000)\n",
        "\n",
        "spm.SentencePieceTrainer.Train(input='arabic_sentences.txt', model_prefix='ara_tokenizer', vocab_size=8000)\n"
      ],
      "metadata": {
        "id": "FVIxjzXdPALz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp_eng = spm.SentencePieceProcessor(model_file='eng_tokenizer.model')\n",
        "sp_ara = spm.SentencePieceProcessor(model_file='ara_tokenizer.model')\n",
        "\n",
        "eng_tokens = [sp_eng.encode(sentence, out_type=int) for sentence in english_sentences]\n",
        "ara_tokens = [sp_ara.encode(sentence, out_type=int) for sentence in arabic_sentences]\n",
        "\n",
        "print(\"Tokenized English:\", eng_tokens[:2])\n",
        "print(\"Tokenized Arabic:\", ara_tokens[:2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8BABltHPGbs",
        "outputId": "c022c377-5898-4ff6-991d-b822813371b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized English: [[5434, 4], [13, 0, 890, 288]]\n",
            "Tokenized Arabic: [[6541, 362, 8], [37, 3650, 293]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_vocab_size = sp_eng.get_piece_size()\n",
        "ara_vocab_size = sp_ara.get_piece_size()\n",
        "\n",
        "eng_id_to_token = {i: sp_eng.id_to_piece(i) for i in range(eng_vocab_size)}\n",
        "ara_id_to_token = {i: sp_ara.id_to_piece(i) for i in range(ara_vocab_size)}\n",
        "\n",
        "eng_token_to_id = {v: k for k, v in eng_id_to_token.items()}\n",
        "ara_token_to_id = {v: k for k, v in ara_id_to_token.items()}\n"
      ],
      "metadata": {
        "id": "d7JxFSShPNM_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "eng_tensors = [torch.tensor(tokens) for tokens in eng_tokens]\n",
        "ara_tensors = [torch.tensor(tokens) for tokens in ara_tokens]\n",
        "\n",
        "eng_padded = pad_sequence(eng_tensors, batch_first=True, padding_value=0)\n",
        "ara_padded = pad_sequence(ara_tensors, batch_first=True, padding_value=0)\n",
        "\n",
        "print(\"Padded English Sentences:\\n\", eng_padded)\n",
        "print(\"Padded Arabic Sentences:\\n\", ara_padded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATg7eS5cPRPt",
        "outputId": "ab8f696e-969e-42a8-ec59-dff762b4f915"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded English Sentences:\n",
            " tensor([[5434,    4,    0,  ...,    0,    0,    0],\n",
            "        [  13,    0,  890,  ...,    0,    0,    0],\n",
            "        [ 102,  153,  185,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 236,  172,  125,  ...,    0,    0,    0],\n",
            "        [   6,  151,  152,  ...,    0,    0,    0],\n",
            "        [  21,   54,   78,  ...,    0,    0,    0]])\n",
            "Padded Arabic Sentences:\n",
            " tensor([[6541,  362,    8,  ...,    0,    0,    0],\n",
            "        [  37, 3650,  293,  ...,    0,    0,    0],\n",
            "        [7852,  293,    0,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 600,   30,   99,  ...,    0,    0,    0],\n",
            "        [2715,    6, 7124,  ...,    0,    0,    0],\n",
            "        [ 144,  729,  108,  ...,    0,    0,    0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "dataset = TensorDataset(eng_padded, ara_padded)\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "for eng_batch, ara_batch in data_loader:\n",
        "    print(\"English Batch:\\n\", eng_batch)\n",
        "    print(\"Arabic Batch:\\n\", ara_batch)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjLo-YYPPWMp",
        "outputId": "85bc71fd-995e-48a2-e978-219f808dc21f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Batch:\n",
            " tensor([[ 203,  194,   21,  ...,    0,    0,    0],\n",
            "        [  73, 3973,   15,  ...,    0,    0,    0],\n",
            "        [1069,   19,  159,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 146,  259,    5,  ...,    0,    0,    0],\n",
            "        [ 271,    6,    3,  ...,    0,    0,    0],\n",
            "        [ 316,    3,  736,  ...,    0,    0,    0]])\n",
            "Arabic Batch:\n",
            " tensor([[ 248, 2114,  125,  ...,    0,    0,    0],\n",
            "        [ 579, 1751,  808,  ...,    0,    0,    0],\n",
            "        [2670,   13,   56,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [  83, 3360, 1884,  ...,    0,    0,    0],\n",
            "        [  10,  504,   34,  ...,    0,    0,    0],\n",
            "        [ 288, 1845, 1553,  ...,    0,    0,    0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcrGcMx8Zez8",
        "outputId": "8cfa9395-4d97-4165-a360-f37bad21db70"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\besher\\appdata\\roaming\\python\\python312\\site-packages (0.2.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuKngTUxZfNU",
        "outputId": "2de098a7-7f4d-4b0f-b5a6-7c4f3af5613a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting torch\n",
            "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\besher\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
            "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.8/203.0 MB 4.2 MB/s eta 0:00:49\n",
            "   ---------------------------------------- 2.1/203.0 MB 5.3 MB/s eta 0:00:38\n",
            "    --------------------------------------- 3.4/203.0 MB 5.8 MB/s eta 0:00:35\n",
            "    --------------------------------------- 4.7/203.0 MB 5.7 MB/s eta 0:00:35\n",
            "   - -------------------------------------- 6.0/203.0 MB 6.1 MB/s eta 0:00:33\n",
            "   - -------------------------------------- 7.3/203.0 MB 6.1 MB/s eta 0:00:32\n",
            "   - -------------------------------------- 8.9/203.0 MB 6.2 MB/s eta 0:00:32\n",
            "   -- ------------------------------------- 10.5/203.0 MB 6.4 MB/s eta 0:00:31\n",
            "   -- ------------------------------------- 11.5/203.0 MB 6.3 MB/s eta 0:00:31\n",
            "   -- ------------------------------------- 12.8/203.0 MB 6.2 MB/s eta 0:00:31\n",
            "   -- ------------------------------------- 14.2/203.0 MB 6.3 MB/s eta 0:00:30\n",
            "   --- ------------------------------------ 15.5/203.0 MB 6.3 MB/s eta 0:00:30\n",
            "   --- ------------------------------------ 16.8/203.0 MB 6.3 MB/s eta 0:00:30\n",
            "   --- ------------------------------------ 18.4/203.0 MB 6.4 MB/s eta 0:00:29\n",
            "   --- ------------------------------------ 19.7/203.0 MB 6.5 MB/s eta 0:00:29\n",
            "   ---- ----------------------------------- 20.7/203.0 MB 6.4 MB/s eta 0:00:29\n",
            "   ---- ----------------------------------- 22.0/203.0 MB 6.3 MB/s eta 0:00:29\n",
            "   ---- ----------------------------------- 23.3/203.0 MB 6.3 MB/s eta 0:00:29\n",
            "   ---- ----------------------------------- 24.9/203.0 MB 6.4 MB/s eta 0:00:28\n",
            "   ----- ---------------------------------- 26.7/203.0 MB 6.5 MB/s eta 0:00:28\n",
            "   ----- ---------------------------------- 28.6/203.0 MB 6.6 MB/s eta 0:00:27\n",
            "   ----- ---------------------------------- 30.1/203.0 MB 6.7 MB/s eta 0:00:26\n",
            "   ------ --------------------------------- 31.7/203.0 MB 6.7 MB/s eta 0:00:26\n",
            "   ------ --------------------------------- 33.8/203.0 MB 6.8 MB/s eta 0:00:25\n",
            "   ------ --------------------------------- 35.4/203.0 MB 6.9 MB/s eta 0:00:25\n",
            "   ------- -------------------------------- 37.2/203.0 MB 7.0 MB/s eta 0:00:24\n",
            "   ------- -------------------------------- 39.1/203.0 MB 7.1 MB/s eta 0:00:24\n",
            "   ------- -------------------------------- 40.1/203.0 MB 6.9 MB/s eta 0:00:24\n",
            "   -------- ------------------------------- 41.7/203.0 MB 7.0 MB/s eta 0:00:24\n",
            "   -------- ------------------------------- 43.5/203.0 MB 7.1 MB/s eta 0:00:23\n",
            "   -------- ------------------------------- 45.4/203.0 MB 7.1 MB/s eta 0:00:23\n",
            "   --------- ------------------------------ 47.2/203.0 MB 7.2 MB/s eta 0:00:22\n",
            "   --------- ------------------------------ 49.0/203.0 MB 7.2 MB/s eta 0:00:22\n",
            "   ---------- ----------------------------- 50.9/203.0 MB 7.3 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 52.7/203.0 MB 7.3 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 54.5/203.0 MB 7.4 MB/s eta 0:00:21\n",
            "   ---------- ----------------------------- 55.8/203.0 MB 7.4 MB/s eta 0:00:20\n",
            "   ----------- ---------------------------- 57.9/203.0 MB 7.4 MB/s eta 0:00:20\n",
            "   ----------- ---------------------------- 59.8/203.0 MB 7.4 MB/s eta 0:00:20\n",
            "   ------------ --------------------------- 61.6/203.0 MB 7.5 MB/s eta 0:00:19\n",
            "   ------------ --------------------------- 63.4/203.0 MB 7.5 MB/s eta 0:00:19\n",
            "   ------------ --------------------------- 65.3/203.0 MB 7.6 MB/s eta 0:00:19\n",
            "   ------------- -------------------------- 67.1/203.0 MB 7.6 MB/s eta 0:00:18\n",
            "   ------------- -------------------------- 68.9/203.0 MB 7.6 MB/s eta 0:00:18\n",
            "   ------------- -------------------------- 70.8/203.0 MB 7.6 MB/s eta 0:00:18\n",
            "   -------------- ------------------------- 72.9/203.0 MB 7.7 MB/s eta 0:00:17\n",
            "   -------------- ------------------------- 73.9/203.0 MB 7.7 MB/s eta 0:00:17\n",
            "   -------------- ------------------------- 76.0/203.0 MB 7.7 MB/s eta 0:00:17\n",
            "   --------------- ------------------------ 77.9/203.0 MB 7.7 MB/s eta 0:00:17\n",
            "   --------------- ------------------------ 79.7/203.0 MB 7.7 MB/s eta 0:00:16\n",
            "   ---------------- ----------------------- 81.5/203.0 MB 7.8 MB/s eta 0:00:16\n",
            "   ---------------- ----------------------- 83.6/203.0 MB 7.8 MB/s eta 0:00:16\n",
            "   ---------------- ----------------------- 84.9/203.0 MB 7.8 MB/s eta 0:00:16\n",
            "   ----------------- ---------------------- 86.5/203.0 MB 7.8 MB/s eta 0:00:16\n",
            "   ----------------- ---------------------- 87.8/203.0 MB 7.7 MB/s eta 0:00:15\n",
            "   ----------------- ---------------------- 89.7/203.0 MB 7.8 MB/s eta 0:00:15\n",
            "   ----------------- ---------------------- 90.7/203.0 MB 7.7 MB/s eta 0:00:15\n",
            "   ------------------ --------------------- 92.5/203.0 MB 7.7 MB/s eta 0:00:15\n",
            "   ------------------ --------------------- 94.1/203.0 MB 7.7 MB/s eta 0:00:15\n",
            "   ------------------ --------------------- 95.9/203.0 MB 7.7 MB/s eta 0:00:14\n",
            "   ------------------- -------------------- 97.8/203.0 MB 7.8 MB/s eta 0:00:14\n",
            "   ------------------- -------------------- 99.4/203.0 MB 7.8 MB/s eta 0:00:14\n",
            "   ------------------- -------------------- 100.9/203.0 MB 7.8 MB/s eta 0:00:14\n",
            "   -------------------- ------------------- 102.8/203.0 MB 7.8 MB/s eta 0:00:13\n",
            "   -------------------- ------------------- 104.6/203.0 MB 7.8 MB/s eta 0:00:13\n",
            "   -------------------- ------------------- 105.9/203.0 MB 7.8 MB/s eta 0:00:13\n",
            "   --------------------- ------------------ 107.2/203.0 MB 7.8 MB/s eta 0:00:13\n",
            "   --------------------- ------------------ 109.1/203.0 MB 7.8 MB/s eta 0:00:13\n",
            "   --------------------- ------------------ 111.1/203.0 MB 7.8 MB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 113.0/203.0 MB 7.8 MB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 114.8/203.0 MB 7.8 MB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 116.7/203.0 MB 7.8 MB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 118.5/203.0 MB 7.9 MB/s eta 0:00:11\n",
            "   ----------------------- ---------------- 120.3/203.0 MB 7.9 MB/s eta 0:00:11\n",
            "   ------------------------ --------------- 122.4/203.0 MB 7.9 MB/s eta 0:00:11\n",
            "   ------------------------ --------------- 123.7/203.0 MB 7.9 MB/s eta 0:00:11\n",
            "   ------------------------ --------------- 125.6/203.0 MB 7.9 MB/s eta 0:00:10\n",
            "   ------------------------- -------------- 127.4/203.0 MB 7.9 MB/s eta 0:00:10\n",
            "   ------------------------- -------------- 129.2/203.0 MB 7.9 MB/s eta 0:00:10\n",
            "   ------------------------- -------------- 130.8/203.0 MB 7.9 MB/s eta 0:00:10\n",
            "   ------------------------- -------------- 131.3/203.0 MB 7.8 MB/s eta 0:00:10\n",
            "   -------------------------- ------------- 132.6/203.0 MB 7.8 MB/s eta 0:00:09\n",
            "   -------------------------- ------------- 134.2/203.0 MB 7.8 MB/s eta 0:00:09\n",
            "   -------------------------- ------------- 135.8/203.0 MB 7.8 MB/s eta 0:00:09\n",
            "   --------------------------- ------------ 137.4/203.0 MB 7.8 MB/s eta 0:00:09\n",
            "   --------------------------- ------------ 138.7/203.0 MB 7.8 MB/s eta 0:00:09\n",
            "   --------------------------- ------------ 140.2/203.0 MB 7.8 MB/s eta 0:00:09\n",
            "   --------------------------- ------------ 141.8/203.0 MB 7.8 MB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 143.1/203.0 MB 7.8 MB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 144.4/203.0 MB 7.8 MB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 146.0/203.0 MB 7.8 MB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 147.3/203.0 MB 7.7 MB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 148.9/203.0 MB 7.7 MB/s eta 0:00:07\n",
            "   ----------------------------- ---------- 150.5/203.0 MB 7.7 MB/s eta 0:00:07\n",
            "   ----------------------------- ---------- 151.8/203.0 MB 7.7 MB/s eta 0:00:07\n",
            "   ------------------------------ --------- 153.1/203.0 MB 7.7 MB/s eta 0:00:07\n",
            "   ------------------------------ --------- 154.7/203.0 MB 7.7 MB/s eta 0:00:07\n",
            "   ------------------------------ --------- 156.0/203.0 MB 7.7 MB/s eta 0:00:07\n",
            "   ------------------------------- -------- 157.5/203.0 MB 7.7 MB/s eta 0:00:06\n",
            "   ------------------------------- -------- 158.6/203.0 MB 7.7 MB/s eta 0:00:06\n",
            "   ------------------------------- -------- 160.2/203.0 MB 7.7 MB/s eta 0:00:06\n",
            "   ------------------------------- -------- 161.2/203.0 MB 7.7 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 162.8/203.0 MB 7.7 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 164.4/203.0 MB 7.7 MB/s eta 0:00:06\n",
            "   -------------------------------- ------- 166.2/203.0 MB 7.7 MB/s eta 0:00:05\n",
            "   --------------------------------- ------ 168.0/203.0 MB 7.7 MB/s eta 0:00:05\n",
            "   --------------------------------- ------ 169.1/203.0 MB 7.6 MB/s eta 0:00:05\n",
            "   --------------------------------- ------ 171.2/203.0 MB 7.7 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 173.0/203.0 MB 7.7 MB/s eta 0:00:04\n",
            "   ---------------------------------- ----- 175.1/203.0 MB 7.7 MB/s eta 0:00:04\n",
            "   ---------------------------------- ----- 177.2/203.0 MB 7.7 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 179.0/203.0 MB 7.7 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 181.1/203.0 MB 7.7 MB/s eta 0:00:03\n",
            "   ----------------------------------- ---- 182.7/203.0 MB 7.8 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 184.0/203.0 MB 7.7 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 186.1/203.0 MB 7.8 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 188.2/203.0 MB 7.8 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 190.1/203.0 MB 7.8 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 191.9/203.0 MB 7.8 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 193.7/203.0 MB 7.8 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 195.8/203.0 MB 7.8 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 197.7/203.0 MB 7.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  199.8/203.0 MB 7.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  201.6/203.0 MB 7.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  202.4/203.0 MB 7.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 203.0/203.0 MB 7.8 MB/s eta 0:00:00\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNi_X-eXZnL9",
        "outputId": "9ebb6a35-7cf2-446d-9dc6-f0bc29c8532b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Besher\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import sentencepiece as spm\n",
        "import random\n",
        "import numpy as np\n",
        "import gc\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "english_sentences = []\n",
        "arabic_sentences = []\n",
        "\n",
        "with open('ara_eng.txt', 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        eng, ara = line.strip().split('\\t')\n",
        "        english_sentences.append(eng)\n",
        "        arabic_sentences.append(ara)\n",
        "\n",
        "print(\"Sample English Sentence:\", english_sentences[0])\n",
        "print(\"Sample Arabic Sentence:\", arabic_sentences[0])\n",
        "\n",
        "\n",
        "with open('english_sentences.txt', 'w', encoding='utf-8') as eng_file:\n",
        "    for sentence in english_sentences:\n",
        "        eng_file.write(sentence + '\\n')\n",
        "\n",
        "with open('arabic_sentences.txt', 'w', encoding='utf-8') as ara_file:\n",
        "    for sentence in arabic_sentences:\n",
        "        ara_file.write(sentence + '\\n')\n",
        "\n",
        "spm.SentencePieceTrainer.Train(input='english_sentences.txt', model_prefix='eng_tokenizer', vocab_size=8000)\n",
        "spm.SentencePieceTrainer.Train(input='arabic_sentences.txt', model_prefix='ara_tokenizer', vocab_size=8000)\n",
        "\n",
        "sp_eng = spm.SentencePieceProcessor(model_file='eng_tokenizer.model')\n",
        "sp_ara = spm.SentencePieceProcessor(model_file='ara_tokenizer.model')\n",
        "\n",
        "del english_sentences, arabic_sentences\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "max_seq_length = 100\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_file, tgt_file, tokenizer_src, tokenizer_tgt, max_length):\n",
        "        self.src_sentences = open(src_file, 'r', encoding='utf-8').readlines()\n",
        "        self.tgt_sentences = open(tgt_file, 'r', encoding='utf-8').readlines()\n",
        "        self.tokenizer_src = tokenizer_src\n",
        "        self.tokenizer_tgt = tokenizer_tgt\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_sentence = self.src_sentences[idx].strip()\n",
        "        tgt_sentence = self.tgt_sentences[idx].strip()\n",
        "        src_tokens = self.tokenizer_src.encode(src_sentence, out_type=int)[:self.max_length]\n",
        "        tgt_tokens = self.tokenizer_tgt.encode(tgt_sentence, out_type=int)[:self.max_length]\n",
        "        return torch.tensor(src_tokens), torch.tensor(tgt_tokens)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    tgt_batch = pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "dataset = TranslationDataset('english_sentences.txt', 'arabic_sentences.txt', sp_eng, sp_ara, max_seq_length)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "batch_size = 16  # Adjust as needed\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "class EmbeddingLayer(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size):\n",
        "        super(EmbeddingLayer, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embedding(x)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_size, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        pe = torch.zeros((max_len, embed_size))\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * (-math.log(10000.0) / embed_size))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, embed_size=256, num_heads=4, num_layers=2, dropout=0.1):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.src_embedding = EmbeddingLayer(src_vocab_size, embed_size)\n",
        "        self.tgt_embedding = EmbeddingLayer(tgt_vocab_size, embed_size)\n",
        "        self.positional_encoding = PositionalEncoding(embed_size, dropout)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=embed_size,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(embed_size, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def create_padding_mask(self, sequences, pad_idx=0):\n",
        "        return (sequences == pad_idx)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_padding_mask = self.create_padding_mask(src)\n",
        "        tgt_padding_mask = self.create_padding_mask(tgt)\n",
        "        memory_key_padding_mask = src_padding_mask.clone()\n",
        "\n",
        "        src = self.positional_encoding(self.src_embedding(src))\n",
        "        tgt = self.positional_encoding(self.tgt_embedding(tgt))\n",
        "\n",
        "        output = self.transformer(\n",
        "            src,\n",
        "            tgt,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_padding_mask,\n",
        "            memory_key_padding_mask=memory_key_padding_mask\n",
        "        )\n",
        "        output = self.fc_out(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "src_vocab_size = sp_eng.get_piece_size()\n",
        "tgt_vocab_size = sp_ara.get_piece_size()\n",
        "model = TransformerModel(src_vocab_size, tgt_vocab_size, embed_size=256, num_heads=4, num_layers=2, dropout=0.1)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
        "\n",
        "\n",
        "def train(model, data_loader, criterion, optimizer, scheduler, num_epochs=10, pad_idx=0):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for src_batch, tgt_batch in data_loader:\n",
        "            src_batch = src_batch.to(device)\n",
        "            tgt_batch = tgt_batch.to(device)\n",
        "\n",
        "            tgt_input = tgt_batch[:, :-1]\n",
        "            tgt_output = tgt_batch[:, 1:]\n",
        "\n",
        "            output = model(src_batch, tgt_input)\n",
        "\n",
        "            output = output.reshape(-1, output.shape[-1])\n",
        "            tgt_output = tgt_output.reshape(-1)\n",
        "\n",
        "            loss = criterion(output, tgt_output)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "        avg_epoch_loss = epoch_loss / len(data_loader)\n",
        "        print(f'Epoch {epoch + 1}, Loss: {avg_epoch_loss:.4f}')\n",
        "\n",
        "def evaluate(model, data_loader, pad_idx=0):\n",
        "    model.eval()\n",
        "    total_bleu_score = 0\n",
        "    total_sentences = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src_batch, tgt_batch in data_loader:\n",
        "            src_batch = src_batch.to(device)\n",
        "            tgt_batch = tgt_batch.to(device)\n",
        "\n",
        "            tgt_input = tgt_batch[:, :-1]\n",
        "            tgt_output = tgt_batch[:, 1:]\n",
        "\n",
        "            output = model(src_batch, tgt_input)\n",
        "            output = output.argmax(dim=-1)\n",
        "\n",
        "            for i in range(tgt_output.size(0)):\n",
        "                reference = [tgt_output[i].tolist()]\n",
        "                candidate = output[i].tolist()\n",
        "                # Remove padding tokens\n",
        "                reference = [[token for token in ref if token != pad_idx] for ref in reference]\n",
        "                candidate = [token for token in candidate if token != pad_idx]\n",
        "                total_bleu_score += sentence_bleu(reference, candidate)\n",
        "                total_sentences += 1\n",
        "\n",
        "    avg_bleu_score = total_bleu_score / total_sentences\n",
        "    print(f'Average BLEU Score: {avg_bleu_score:.4f}')\n",
        "\n",
        "\n",
        "train(model, train_loader, criterion, optimizer, scheduler, num_epochs=10, pad_idx=0)\n",
        "\n",
        "\n",
        "evaluate(model, val_loader, pad_idx=0)\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'transformer_model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhjtJFpLZrWc",
        "outputId": "24dacf1b-e586-46d7-c5dd-b3ce2d4d5b01"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Sample English Sentence: Hi.\n",
            "Sample Arabic Sentence: مرحبًا.\n",
            "Epoch 1, Loss: 5.8666\n",
            "Epoch 2, Loss: 3.2910\n",
            "Epoch 3, Loss: 1.7649\n",
            "Epoch 4, Loss: 1.1056\n",
            "Epoch 5, Loss: 0.7678\n",
            "Epoch 6, Loss: 0.5619\n",
            "Epoch 7, Loss: 0.4288\n",
            "Epoch 8, Loss: 0.3348\n",
            "Epoch 9, Loss: 0.2653\n",
            "Epoch 10, Loss: 0.2155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Besher\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "C:\\Users\\Besher\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "C:\\Users\\Besher\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:180.)\n",
            "  output = torch._nested_tensor_from_mask(\n",
            "C:\\Users\\Besher\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU Score: 0.2378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average BLEU Score: 0.2378\n"
      ],
      "metadata": {
        "id": "nKdd08R2-sap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_score import score\n",
        "\n",
        "def compute_bert_score(model, data_loader, sp_src, sp_tgt, pad_idx=0):\n",
        "    \"\"\"Compute BERTScore for translations.\"\"\"\n",
        "    model.eval()\n",
        "    references = []\n",
        "    candidates = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src_batch, tgt_batch in data_loader:\n",
        "            src_batch = src_batch.to(device)\n",
        "            tgt_batch = tgt_batch.to(device)\n",
        "\n",
        "            tgt_input = tgt_batch[:, :-1]\n",
        "            tgt_output = tgt_batch[:, 1:]\n",
        "\n",
        "            output = model(src_batch, tgt_input)\n",
        "            output = output.argmax(dim=-1)\n",
        "\n",
        "            for i in range(tgt_output.size(0)):\n",
        "                # Decode reference and candidate sentences\n",
        "                ref_sentence = sp_tgt.decode([token for token in tgt_output[i].tolist() if token != pad_idx])\n",
        "                candidate_sentence = sp_tgt.decode([token for token in output[i].tolist() if token != pad_idx])\n",
        "\n",
        "                references.append(ref_sentence)\n",
        "                candidates.append(candidate_sentence)\n",
        "\n",
        "    # Compute BERTScore\n",
        "    P, R, F1 = score(candidates, references, lang=\"ar\")  # Set \"lang\" to Arabic (\"ar\")\n",
        "    avg_f1 = F1.mean().item()\n",
        "\n",
        "    print(f\"Average BERTScore (F1): {avg_f1:.4f}\")\n",
        "    return P, R, F1\n"
      ],
      "metadata": {
        "id": "I3zixetf-Pbz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P, R, F1 = compute_bert_score(model, val_loader, sp_eng, sp_ara, pad_idx=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwrxrI-m-cCK",
        "outputId": "8e823156-e075-49e9-9edc-728e3bf90d53"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BERTScore (F1): 0.7342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average BERTScore (F1): 0.7342"
      ],
      "metadata": {
        "id": "5u6WnqIJ-xh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def compute_bleu_scores(model, data_loader, pad_idx=0):\n",
        "    \"\"\"Compute BLEU scores for all samples in the validation dataset.\"\"\"\n",
        "    model.eval()\n",
        "    bleu_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src_batch, tgt_batch in data_loader:\n",
        "            src_batch = src_batch.to(device)\n",
        "            tgt_batch = tgt_batch.to(device)\n",
        "\n",
        "            tgt_input = tgt_batch[:, :-1]\n",
        "            tgt_output = tgt_batch[:, 1:]\n",
        "\n",
        "            output = model(src_batch, tgt_input)\n",
        "            output = output.argmax(dim=-1)\n",
        "\n",
        "            for i in range(tgt_output.size(0)):\n",
        "                reference = [tgt_output[i].tolist()]\n",
        "                candidate = output[i].tolist()\n",
        "                # Remove padding tokens\n",
        "                reference = [[token for token in ref if token != pad_idx] for ref in reference]\n",
        "                candidate = [token for token in candidate if token != pad_idx]\n",
        "                bleu_score = sentence_bleu(reference, candidate)\n",
        "                bleu_scores.append(bleu_score)\n",
        "\n",
        "    return np.array(bleu_scores)\n",
        "\n",
        "def bootstrap_confidence_interval(data, num_samples=1000, confidence_level=0.95):\n",
        "    \"\"\"Compute the confidence interval for the mean using bootstrap sampling.\"\"\"\n",
        "    bootstrapped_means = []\n",
        "    n = len(data)\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        sample = np.random.choice(data, size=n, replace=True)\n",
        "        bootstrapped_means.append(np.mean(sample))\n",
        "\n",
        "    lower_bound = np.percentile(bootstrapped_means, (1 - confidence_level) / 2 * 100)\n",
        "    upper_bound = np.percentile(bootstrapped_means, (1 + confidence_level) / 2 * 100)\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Compute BLEU scores\n",
        "bleu_scores = compute_bleu_scores(model, val_loader)\n",
        "\n",
        "# Compute 95% confidence interval\n",
        "lower, upper = bootstrap_confidence_interval(bleu_scores)\n",
        "print(f\"Average BLEU Score: {np.mean(bleu_scores):.4f}\")\n",
        "print(f\"95% Confidence Interval: [{lower:.4f}, {upper:.4f}]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_PPDrPb8RfX",
        "outputId": "9a5509d4-db00-4d97-8826-cf7645683fc9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU Score: 0.2378\n",
            "95% Confidence Interval: [0.2294, 0.2450]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 95% Confidence Interval: [0.2294, 0.2450]"
      ],
      "metadata": {
        "id": "BOmvpn8b-_Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s-ARdgRlH1dE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}